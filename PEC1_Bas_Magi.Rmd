---
title: "Regresi√≥n, modelos y m√©todos Prueba de evaluaci√≥n continua 1"
author: "Bas_Mag√≠_Catasus"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
  pdf_document:
    keep_tex: yes
header-includes: \usepackage[utf8]{inputenc}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Ejercicio 1

**Un grupo de cient√≠ficos norteamericanos est√°n interesados en encontrar un h√°bitat adecuado para reintroducir una especie rara de escara- bajos tigre, llamada cicindela dorsalis dorsalis, los cuales viven en playas de arena de la costa del Atl√°ntico Norte. Se muestrearon 12 playas y se midi√≥ la densidad de estos escarabajos tigre. Adicionalmente se midieron una serie de facto- res bi√≥ticos y abi√≥ticos tales como la exposici√≥n a las olas, tama√±o de la part√≠cula de arena, pen- diente de la playa y densidad de los anf√≠podos depredadores.**

```{r}
library(readxl)
cicindela= read_excel("cicindela.xlsx")
```

**(a) Ajustar un modelo de regresi√≥n lineal m√∫ltiple que estime todos los coeficientes de regresi√≥n parciales referentes a todas las variables regresoras y el intercepto.**

**¬øEs significativo el modelo obtenido? ¬øQu√© test estad√≠stico se emplea para contestar a esta pregunta. Plantear la hip√≥tesis nula y la alternativa del test.**

**¬øQu√© variables han salido significativas para un nivel de significaci√≥n Œ± = 0.10?**

```{r}
names(cicindela)
```

Para ajustar el modelo de regresi√≥n lineal cogeremos la varaible "BeetleDesity" como variable dependiente (y).

-   BeetleDensity: la densidad de escarabajos tigre (variable dependiente).

-   Wave exposure: la exposici√≥n a las olas.

-   Sandparticlesize: el tama√±o de la part√≠cula de arena.

-   Beach steepness: la pendiente de la playa.

-   AmphipodDensity: la densidad de los anf√≠podos depredadores.

```{r}
cici_model = lm(BeetleDensity ~ `Wave exposure` + Sandparticlesize + `Beach steepness` + AmphipodDensity, data = cicindela)
summary(cici_model)
```

El modelo lineal planteado parece ser significativo seg√∫n el valor del F-estad√≠sitico, el cual compara la varianza explicada vs la no explicada.

H0: Coeficientes de regresi√≥n = 0; el modelo no predictivo

H1: Coeficientes de regresi√≥n != 0; el modelo es predictivo

El valor del estad√≠stico F es 39.71 con 4 y 7 grados de libertad, y el p-valor es 6.727e-05, lo que indica que rechazamos la hip√≥tesis nula y aceptamos la hip√≥tesis alternativa. Concluimos que al menos una de las variables independientes tiene un efecto significativo sobre la variable dependiente, y que el modelo de regresi√≥n lineal m√∫ltiple proporciona un ajuste significativo a los datos.

H1: üü¢

**(b) Calcular los intervalos de confianza al 90 y 95 % para el par√°metro que acompa√±a a la variable AmphipodDensity. Utilizando s√≥lo estos intervalos, ¬øqu√© podr√≠amos haber deducido sobre el p-valor para la densidad de los anf√≠podos depredadores en el resumen del modelo de regresi√≥n? ¬øQu√© interpretaci√≥n pr√°ctica tiene este par√°metro Œ≤4?**

```{r}
confint(cici_model, level = 0.9)
```

```{r}
confint(cici_model, level = 0.95)
```

Si solo tuvi√©ramos esta informaci√≥n, no podr√≠amos deducir el p-valor exacto para AmphipodDensity, pero podr√≠amos decir que el intervalo de confianza al 90% no incluye el valor 0, lo que sugiere que el coeficiente es significativamente diferente de cero a un nivel de significaci√≥n del 10%. Sin embargo, el intervalo de confianza al 95% incluye el valor 0, lo que sugiere que no hay evidencia suficiente para rechazar la hip√≥tesis nula de que el coeficiente es igual a cero a un nivel de significaci√≥n del 5%.

El par√°metro Œ≤4, que acompa√±a a la variable AmphipodDensity, representa la relaci√≥n entre la densidad de los anf√≠podos depredadores y la densidad de escarabajos, despu√©s de tener en cuenta los efectos de las otras variables en el modelo. Por lo tanto, un valor negativo de este par√°metro sugiere que a medida que aumenta la densidad de los anf√≠podos depredadores, disminuye la densidad de los escarabajos.

**(c) Estudiar la posible multicolinealidad del modelo con todas las regresoras calculando los VIFs**

```{r}
library(DescTools)
VIF(cici_model)
```

Por lo general, podemos decir que con valores de VIF \< 5 no existen problemas de multicolinealidad. En este caso solo tenemos un valor no muy superior a 5 con la variable AmphipodDensity. En este caso, el valor VIF para la variable **`AmphipodDensity`** es cercano a 5, lo que podr√≠a indicar una ligera multicolinealidad, pero a√∫n est√° dentro de un rango aceptable. Habr√° que tener esto en cuenta a la hora de sacar conclusiones de los resultados.

**(d) Considerar el modelo m√°s reducido que no incluye las variables exposici√≥n a las olas y la pendiente de la playa y decidir si nos podemos quedar con este modelo reducido mediante un contraste de modelos con el test F para un Œ± = 0.05. Escribir en forma param√©trica las hip√≥tesis H0 y H1 de este contraste. Comparar el ajuste de ambos modelos**

```{r}
cici_reducido = lm(cicindela$BeetleDensity ~ cicindela$Sandparticlesize + cicindela$AmphipodDensity)
summary(cici_reducido)
```

-   H0: Los coeficientes de las variables eliminadas son iguales a cero, es decir, el modelo reducido no es significativamente peor que el modelo completo.

-   H1: Al menos uno de los coeficientes de las variables eliminadas no es igual a cero, es decir, el modelo completo es significativamente mejor que el modelo reducido.

```{r}
# Comparaci√≥n de los modelos
anova(cici_reducido, cici_model)
```

H0: üü¢

La suma de cuadrados de los residuos en el modelo reducido es de 192.20, y los grados de libertad son 9. Esto significa que el modelo reducido explica el 94.31% de la varianza de la variable respuesta, y que la variable "Sandparticlesize" y "AmphipodDensity" son suficientes para explicar la mayor parte de la variabilidad de "BeetleDensity".

**(e) Calcular y dibujar una regi√≥n de confianza conjunta al 95 % para los par√°metros asociados con Sandparticlesize y AmphipodDensity con el modelo que resulta del apartado anterior**

**Dibujar el origen de coordenadas. La ubicaci√≥n del origen respecto a la regi√≥n de confianza nos indica el resultado de una determinada prueba de hip√≥tesis. Enunciar dicha prueba y su resultado.**

```{r}
confint(cici_reducido)
```

```{r}
library(ggplot2)
ggplot(cicindela, aes(x = Sandparticlesize, y = AmphipodDensity)) + 
  geom_point() +
  stat_ellipse(type = "norm", level = 0.95) +
  scale_fill_manual(values = "blue", name = "Confidence Interval") +
  theme_bw() +
  labs(x = "Sand Particle Size", y = "Amphipod Density")

# No he podido hacerlo con ellipse() ya que parece que no funciona correctamente
```

**(f) Con el modelo reducido del apartado (d), predecir en forma de intervalo de confianza al 95 % la densidad de los escarabajos tigre previsible para una playa cercana a un conocido hotel donde el tama√±o de part√≠cula de arena es 5 y la densidad de anf√≠podos depredadores es 11. Comprobar previamente que los valores observados no suponen una extrapolaci√≥n**

```{r}
# Verificamos los valores
summary(cicindela[c("Sandparticlesize", "AmphipodDensity")])

```

Los valores estan dentro del rango

```{r}
# Valores predictores
valores <- data.frame(5, 11)

# Predicci√≥n al 95%
predict(cici_reducido, valores, interval = "confidence")
```

# Ejercicio 2

**En el trabajo de Whitman et al. (2004) se estu- dia, entre otras cosas, la relaci√≥n entre la edad de los leones y la proporci√≥n oscura en la colo- raci√≥n de sus narices. En el archivo lions.csv disponemos de los datos de 105 leones machos y hembras de dos √°reas de Tanzania, el parque na- cional de Serengueti y el cr√°ter del Ngorongoro, entre 1999 y 2002. Las variables registradas son la edad conocida de cada animal y la propor- ci√≥n oscura de su nariz a partir de fotograf√≠as tratadas digitalmente (ver figura adjunta). En la figura 1 se reproduce el gr√°fico de disper- si√≥n de la figura 4 del art√≠culo con el cambio de coloraci√≥n de la nariz seg√∫n la edad de machos y hembras en las dos poblaciones separadas. Nota: Los datos se han extra√≠do principalmente del gr√°fico del art√≠culo de Whitman et al. (2004) y por lo tanto son aproximados. Algunos pa- quetes de R contienen un data.frame con una parte de estos datos. Por ejemplo LionNoses del paquete abd contiene los datos de todos los machos. En consecuencia, los resultados num√©- ricos de vuestro an√°lisis pueden ser ligeramente distintos a los del trabajo original.**

```{r}
# Importamos el dataset
leon = read.csv("lions.csv")
```

**(a) Reproducir el gr√°fico de dispersi√≥n de la figura 1 (figura 4d del art√≠culo) lo m√°s fielmente posible al original, ya que se trata de una exigencia de los editores de la revista**

```{r}
# Grafico
library(ggplot2)
ggplot(leon, aes(x=age, y=prop.black))+
  geom_point(aes(shape = area), size = 2) +
  geom_point(aes(shape = sex), size=2) + 
  labs(title = "Figure 4",
       x = "Age (yr)", y = "Proportion black") + 
  scale_shape_manual(values = c(3, 19, 4, 17),
                     labels = c("Serengueti Females", "Serengueti Males",
                                "Ngorongoro Females", "Ngorongoro Males"))
```

**(b) En el art√≠culo se destacan los siguientes resultados:**

***After controlling for age, there was no effect of sex on nose colour in the Serengeti, but Ngorongoro males had lighter noses than Ngorongoro females.***

**Ajustar un primer modelo sin considerar la posible interacci√≥n entre el sexo y las √°reas y contrastar si el sexo es significativo en el modelo as√≠ ajustado y en los modelos separados seg√∫n el √°rea**

```{r}
# Pasar a factores
lion= data.frame(prop.black = leon$prop.black,
                       age = leon$age,
                       sex = factor(leon$sex),
                       area = factor(leon$area))

```

```{r}
# Contrastar si el sexo es significativo en el modelo as√≠ ajustado
leo_model1= lm(lion$prop.black ~ lion$age + lion$sex)
summary(leo_model1)
```

Parece que el sexo si es significativo en este modelo.\

```{r}
# Modelos separados segun el area
leo_S= subset(leon, area == 'S')
leo_N= subset(leon, area == 'N')

leo_model2.1= lm(leo_S$prop.black ~ leo_S$age * leo_S$sex)
summary(leo_model2.1)
```

```{r}
leo_model2.2=lm(leo_N$prop.black ~ leo_N$age * leo_N$sex)
summary(leo_model2.2)
```

En el modelo del Serengueti existen diferencias significativa por lo que respecta a la proporci√≥n oscura de la nariz, mientras que en el modelo de Nogorongoro no. Veamoslo gr√°ficamente:

```{r}
model2.1= ggplot(leo_S, aes(x = sex, y = prop.black)) +
  geom_boxplot()+
  labs(title = "Serengueti",
       x = "Sex", y = "Proporci√≥n oscura de la nariz") + 
  theme(plot.title = element_text(hjust = 0.5))
model2.2= ggplot(leo_N, aes(x = sex, y = prop.black)) +
  geom_boxplot()+
  labs(title = "Ngorongoro",
       x = "Sex", y = "Proporci√≥n oscura de la nariz") + 
  theme(plot.title = element_text(hjust = 0.5))

library(gridExtra)
grid.arrange(model2.1, model2.2, ncol=2)

```

**(c) Otro resultado destacado es que para los machos hay diferencias seg√∫n el √°rea. Contrastar este resultado y dibujar las rectas de regresi√≥n para las dos √°reas que se obtienen del modelo**

```{r}
# Solo machos
leo_M= subset(x= leon, sex =='M')

library(tidyr)
#Filtrar Segrengueti
serengeti_males = subset(leo_M, area == 'S')

# Filtrar Nogorongoro
nogorongoro_males = subset(leo_M, area == 'N')

# Modelo lineal para Serengeti
serengeti_model= lm(prop.black ~ age, data = serengeti_males)

# Modelo lineal para Ngorongoro
ngorongoro_model= lm(prop.black ~ age, data = nogorongoro_males)


# Comparativa de los modelos
serengeti_summary = summary(serengeti_model)

ngorongoro_summary = summary(ngorongoro_model)

tabla_comparativa = data.frame(
  Area = c("Serengeti", "Ngorongoro"),
  R_squared = c(serengeti_summary$r.squared, ngorongoro_summary$r.squared),
  Std_error = c(serengeti_summary$sigma, ngorongoro_summary$sigma),
  P_value = c(serengeti_summary$coefficients[2, 4],
              ngorongoro_summary$coefficients[2, 4])
)

print(tabla_comparativa)
```

Visto los resultados, parece que existen diferencias significativas entre los machos de las distintas regiones.La R-cuadrada para Serengeti es mayor que para Ngorongoro, lo que sugiere que el modelo de regresi√≥n lineal ajusta mejor a los datos para la regi√≥n de Serengeti.

Ahora pasamos a observar las diferencias gr√°ficamente:

```{r}
# Rectas
library(ggplot2)

ggplot(leo_M, aes(x = age, y = prop.black, shape = area)) +
  geom_point(size = 2) +
  geom_smooth(aes(color = area), method = "lm", se = FALSE, formula = y ~ x, data = serengeti_males) +
  geom_smooth(aes(color = area), method = "lm", se = FALSE, formula = y ~ x, data = nogorongoro_males) +
  labs(title = "Proportion of black in male lions by region",
       x = "Age (yr)", y = "Proportion black male",
       shape = "Region", color = "Region") +
  scale_shape_manual(values = c(22, 21)) +
  scale_color_manual(values = c("#0072B2", "#D55E00"))

```

```{r}
# Boxplot
ggplot(leo_M, aes(x = area, y = prop.black)) +
  geom_boxplot()+
  labs(title = "Machos",
       x = "Area", y = "Proporci√≥n oscura de la nariz") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  scale_x_discrete(labels = c("Serengueti", "Ngorongoro"))
```

Los machos del Serengueti tienen, significativamente, unas narices m√°s oscuras que los machos de Ngorongoro.

**(d) En la tabla 1 del art√≠culo de Whitman et al. se dan los intervalos de confianza al 95 %, al 75 % y al 50 % para predecir la edad de una leona de 10 a√±os o menos seg√∫n su proporci√≥n de pigmentaci√≥n oscura en la nariz. La primera cuesti√≥n es: ¬øsirven para esto los modelos estudiados en los apartados anteriores?**

No, son modelos de regresi√≥n lineal pero no relacionan directamente leonas con su pigmentaci√≥n oscura de la nariz y la edad.

**Reproducir la fila de la tabla 1 para una proporci√≥n del 0.50 seg√∫n el modelo que proponen en el art√≠culo**

**Nota: Recordemos tambi√©n aqu√≠ que los resultados pueden ser ligeramente distintos a los del art√≠culo por la utilizaci√≥n de datos aproximados.**

```{r}
# Modelo del articulo
intercept = 2.00667
B1 = 5.9037
x = 0.5

y = intercept + B1*asin(x)
se = 1.23

# Crear los vectores de los intervalos
intervalos_95= paste(round(y - 1.96*se, 2), round(y + 1.96*se, 2), sep=" - ")
intervalos_75 = paste(round(y - 1.15*se, 2), round(y + 1.15*se, 2), sep=" - ")
intervalos_50 = paste(round(y - 0.67*se, 2), round(y + 0.67*se, 2), sep=" - ")

# Imprimir los resultados

Table_1 = data.frame(
  'Proportion black' = x,
  'Estimated age in years (s.e.)' = y,
  '95 p.i.' = intervalos_95,
  "75 p.i." = intervalos_75,
  '50 p.i.' = intervalos_50
)

Table_1
```

**Aclarar un detalle: lo que en la tabla 1 del art√≠culo se llama s.e., standard error ¬øqu√© es exactamente?**

El error est√°ndar (s.e.) es una medida de la variabilidad de una estimaci√≥n estad√≠stica, como la media o el coeficiente de regresi√≥n. En el contexto de la tabla del art√≠culo que estamos analizando, el s.e. se refiere a la incertidumbre asociada con la estimaci√≥n de la edad en a√±os a partir de la proporci√≥n de negros en la nariz de las aves.

En t√©rminos m√°s t√©cnicos, el s.e. representa la desviaci√≥n est√°ndar de la distribuci√≥n de las estimaciones obtenidas a partir de diferentes muestras de la misma poblaci√≥n. Un s.e. m√°s bajo indica que la estimaci√≥n es m√°s precisa, mientras que un s.e. m√°s alto indica que la estimaci√≥n es menos precisa.

# Ejercicio 3

**Verificar las hip√≥tesis de Gauss-Markov y la normalidad de los residuos del modelo completo del apartado (b) del ejercicio 2. Realizar una completa diagnosis del modelo para ver si se cumplen las condiciones del modelo de regresi√≥n: normalidad, homocedasticidad,. . . y estudiar la presencia de valores at√≠picos de alto leverage y/o puntos influyentes.**

**Construir los gr√°ficos correspondientes y justificar su interpretaci√≥n. ¬øPodemos considerar el modelo ajustado como fiable?**

```{r}
# Linealidad
par(mfrow = c(2, 2))

plot(leo_model1, 1)
title("Modelo 1")
plot(leo_model2.1, 1)
title("Modelo 2.1")
plot(leo_model2.2, 1)
title("Modelo 2.2")

main_title = "Linealidad"
title(main = main_title, outer = TRUE, line= -1)

```

Parece que todos los modelos pasan el test de linealidad.

```{r}
# Normalidad de residuos
par(mfrow = c(2, 2))

plot(leo_model1, 2)
title("Modelo 1")
plot(leo_model2.1, 2)
title("Modelo 2.1")
plot(leo_model2.2, 2)
title("Modelo 2.2")

main_title = "Normalidad de residuos"
title(main = main_title, outer = TRUE, line= -1)
```

Parece que todos los modelos siguen una normalidad en los residuos, realizamos Shapiro para corroborar:

```{r}
# Prueba de Shapiro-Wilk para los residuos del modelo 1
p_values <- c(shapiro.test(leo_model1$residuals)$p.value,
              shapiro.test(leo_model2.1$residuals)$p.value,
              shapiro.test(leo_model2.2$residuals)$p.value)

model_names <- c("Modelo 1", "Modelo 2.1", "Modelo 2.2")

table_p_values <- data.frame(Modelo = model_names, Pvalue = p_values)

table_p_values
```

*[H0: Normal; H1: No normal]*

El valor de p-value para el modelo 2.2 es de 0.567, lo que indica que no hay suficiente evidencia para rechazar la hip√≥tesis nula de normalidad en los residuos para este modelo. Por otro lado, tanto el modelo 1 como el modelo 2.1 tienen valores de p-value por debajo de 0.05, lo que sugiere que hay evidencia suficiente para rechazar la hip√≥tesis nula de normalidad en los residuos para estos modelos.

En resumen, se puede decir que los modelos 1 y 2.1 no cumplen con la suposici√≥n de normalidad en los residuos, mientras que el modelo 2.2 s√≠ la cumple.

```{r}
#Homocedasticidad de residuos o homogeneidad de varianzas
par(mfrow = c(2, 2))

plot(leo_model1, 3)
title("Modelo 1")
plot(leo_model2.1, 3)
title("Modelo 2.1")
plot(leo_model2.2, 3)
title("Modelo 2.2")

main_title = "Homocedasticidad"
title(main = main_title, outer = TRUE, line= -1)

```

```{r}
# Test BP
library(car)
p_values= c(ncvTest(leo_model1)$p,
              ncvTest(leo_model2.1)$p,
              ncvTest(leo_model2.2)$p)
              

model_names=  c("Modelo 1", "Modelo 2.1", "Modelo 2.2")

table_BP= data.frame(Modelo = model_names, Pvalue = p_values)

table_BP
```

*[H0: Homocedasticidad; H1: No homocedasticidad]*

Los valores de p obtenidos del test de Breusch-Pagan indican que el modelo 1 y el modelo 2.1 no presentan heterocedasticidad significativa, ya que sus valores de p son menores a 0.05, mientras que el modelo 2.2 presenta evidencia de heterocedasticidad, ya que su valor de p es mayor a 0.05.

En resumen, el modelo 2.2 parece ser el que mejor cumple con los supuestos de linealidad, normalidad de residuos y homocedasticidad.

```{r}
# Valores influyentes
par(mfrow = c(2, 2))

plot(leo_model1, 4)
title("Modelo 1")
plot(leo_model2.1, 4)
title("Modelo 2.1")
plot(leo_model2.2, 4)
title("Modelo 2.2")

main_title = "Valores influyentes"
title(main = main_title, outer = TRUE, line= -1)

```

Una observacion influyente se define como una observaci√≥n que se diferencia marcadamente del conjunto de datos y tiene una gran influencia en el resultado del modelo, es decir, que no solo son outliers.

Pueden presentar un problema porque afectan los coeficientes de la ecuaci√≥n y generan errores de predicci√≥n

Para detectarlos se utilizan medidas de influencia, entre las que resalta la distancia de Cook. LA distancia de Cook indica que un caso es un valor influyente cuando DCook \>=1

```{r}
# Distancia de cook
leon$cook <- cooks.distance(leo_model1)
which(leon$cook > 1)
#leon$cook <- cooks.distance(leo_model2.1)
which(leon$cook2.1 > 1)
leon$cook <- cooks.distance(leo_model2.2)
which(leon$cook2.2 > 1)
```

```{r}
# Valores at√≠picos alto leverage
library(outliers)
upper_test= grubbs.test(leo_model2.2$residuals)
upper_test
```

El resultado del Grubbs test indica que no se encontr√≥ evidencia suficiente para rechazar la hip√≥tesis nula de que el valor m√°s alto en los residuos del modelo sea un outlier. El p-value es mayor que el nivel de significancia est√°ndar de 0.05, lo que sugiere que no hay suficiente evidencia para concluir que el valor es significativamente diferente del resto de los valores.

Usamos solo el modelo2.2 porque es al √∫nico que hemos podido constatar normalidad de los residuos.

```{r}
lower_test= grubbs.test(leo_model2.2$residuals, opposite = TRUE)
lower_test
```

El valor p es 1. Al nivel de significancia del 5%, no rechazamos la hip√≥tesis de que el valor m√°s bajo -0.34 no es un valor at√≠pico.

Aun as√≠ vemos en los gr√°ficos de boxplot, como en el modelo de Nogorongoro hay 3 valores que seguramente sean outliers, aunque no podemos aplicar Grubbs, ya que el modelo 2.2 no sigue una regresi√≥n lineal seg√∫n nuestro an√°lisis.

**Teniendo en cuenta que la variable respuesta de la regresi√≥n del apartado (b) del ejercicio 2 es una proporci√≥n, ¬øpresenta alg√∫n problema este modelo? ¬øQu√© alternativas nos podemos plantear para mejorar el ajuste de los datos?**

S√≠, puede haber problemas al utilizar un modelo de regresi√≥n lineal para predecir proporciones ya que las proporciones est√°n restringidas en el rango [0,1]. Es decir, la variable de respuesta no sigue una distribuci√≥n normal y puede haber problemas con los supuestos de homocedasticidad y normalidad.

Hay dos vias; una alternativa seria utilizar modelos de regresi√≥n no lineal, como modelos log√≠sticos o modelos de regresi√≥n beta. O, otra alternativa seria, transformar la variable respuesta para cumplir con los supuestos de linealidad.

**Atendiendo a la naturaleza de la variable respuesta, ¬øhay alguna transformaci√≥n adecuada?**

S√≠, puede ser adecuada la transformaci√≥n de la variable a logit. La transformaci√≥n logit se utiliza com√∫nmente para datos de proporciones y tiene la ventaja de que los valores transformados est√°n acotados entre -‚àû y +‚àû.

**Aplicar la transformaci√≥n m√°s adecuada a la variable respuesta del modelo considerado. Comparar los dos modelos: con y sin la transformaci√≥n. ¬øQu√© modelo es mejor? Justificar la respuesta**

```{r}
# Aplicamos logit
library(arm)
leo_model_logit = glm(prop.black ~ age + sex + area, data = leon, family = binomial)
summary(leo_model_logit)

```

```{r}
# Sin aplicar logit
leo_model_no_logit = lm(prop.black ~ age + sex + area, data = leon)
summary(leo_model_no_logit)

```

**Realizar una r√°pida diagnosis del modelo transformado. ¬øEstamos satisfechos con este nuevo modelo? ¬øQu√© otro ajuste nos podemos plantear para mejorar el modelo?**

```{r}
plot(leo_model_logit, 1)
```

```{r}
par(mfrow = c(1, 2))
plot(hatvalues(leo_model_logit),
     xlab = "Observation", ylab = "Leverage",
     main = "Leverage Plot")
abline(h = 2 * mean(hatvalues(leo_model_logit)),
       col = "red", lty = 2)
plot(cooks.distance(leo_model_logit),
     xlab = "Observation", ylab = "Cook's Distance",
     main = "Cook's Distance Plot")
abline(h = 2 * mean(cooks.distance(leo_model_logit)),
       col = "red", lty = 2)

```

En general, podemos decir que estamos satisfechos con este nuevo modelo. Si queremos mejorar el modelo, podemos plantear otras transformaciones para la variable respuesta, o incluso probar con otros tipos de modelos, como modelos no lineales. Sin embargo, esto depender√° del contexto y de los objetivos espec√≠ficos del an√°lisis.

**\
Discutir la utilizaci√≥n de la transformaci√≥n arcoseno en el modelo del apartado (d) del ejercicio 2**

```{r}
# Ajustar la variable respuesta
prop.arcoseno= asin(sqrt(leon$prop.black))
prop.arcoseno = pmin(prop.arcoseno, 1)

# Ajustar el modelo
modelo_arcoseno= glm(prop.arcoseno ~ age + sex + area, data = leon, family = binomial)

prop.arcoseno_pred <- predict(modelo_arcoseno, type = "response")
prop.pred <- sin(prop.arcoseno_pred)^2


summary(modelo_arcoseno)
```

En general, este modelo parece ser mejor que el modelo original ya que cumple con los supuestos del modelo lineal generalizado y tiene una deviance residual menor. Sin embargo, la transformaci√≥n arcoseno puede dificultar la interpretaci√≥n de los resultados y, en algunos casos, puede ser preferible utilizar otros m√©todos de transformaci√≥n.
