# Regresi贸n Lineal: Requisitos

Font: Data Pol铆tica (<https://www.youtube.com/watch?v=FGpfhKwsluE&list=WL&index=1>)

```{r}
# Abrimos la base de datos
if(!require('rio')){install.packages("rio")}
library(rio)
ruta_data=file.choose()
data = import(ruta_data)
```

```{r}
# Construimos el modelo
formula= data$salario_actual~data$salario_inicial + data$experiencia + data$antiguedad
modelo=lm(formula)
summary(modelo)
```

Preguntas para poder validar un modelo:

-   p-valor \< 0.05 =\> Modelo vlido 

-   R虏 Ajustado =\> Explica un 80% de la variabilitat de y

-   Cada una de les variables independents aporta al model

# Supuestos

Para verifiacar un modelo lineal necessitamos verificar que se cumplan los siguientes supuestos:

-   Linealidad

-   Normalidad de residuos

-   Homocedasticidad (Hmogeneidad de variancias)

-   Ausencia de multicolinealidad

-   Ausencia de valores influyentes

## Linealidad

La linealidad se produce cuando exsite relacion linela entre las varaibles independientes y la varaible dependiente.

**驴Porque es un problema cuando no se cumple?**

Porque se pueden considerar variables que no aporten al modelo. Tambien porque pueden existir otras relaciones no lineales que no son vistas previamente.

**驴Como detectarlo?**

Con verificaci贸n grfica: Diagrama de dispersi贸n entre los valores predichos y los residuos (la l铆nea de tenencia debe ser horizontal) O pruebas de linealidad para cada una de las varaibles independientes.

```{r}
plot(modelo, 1)
```

Vemos un grafico de los valores predixos i cada uno de los residuos, la linea roja se aleja de la linia puntual. Solo viendo el grafico podriamos decir que hay un problema en el supuesto de linealidad, tendriamos que verificar linealida para cada una de las varaibales independientes con la dependiente.

```{r}
cor.test(data$salario_actual, data$salario_inicial)
```

**Test de Pearson**

*[(p-value \< 0.05) = (H0: No existe correlacion lineal; H1: Existe correlaci贸n lineal)]*

Relaci贸n lineal 

```{r}
cor.test(data$salario_actual, data$experiencia)
```



```{r}
cor.test(data$salario_actual, data$antiguedad)
```

 No cumple linealidad con la variable independiente, podriamos excluirla o analizar porque no es lineal.

## Normalidad de residuos

La normalidad de residuos existe cuando los residuos (no tipificados) del modelo no siguen una distribuci贸n normal.

**驴Porque es un problema cuando no se cumple?**

Porque no se podr铆an aplicar pruebas de validaci贸n global del modelo (ANOVA). Estas tienen como principal requerimiento que exista normalidad.

**驴Como detectarlo?**

Con un qqplot o realizar una prueba de normalidad (Shapiro Test)

```{r}
# Grfico
plot(modelo, 2)
```

En un supuesto de liniealidad esperamos ver como todos los residuos siguen la linia daigonal. En este casa, y aunque la mayoria de puntos lo cumplen tenemos una disperci贸n hacia el final e inicio del grfico, para una cuantificaci贸n del supuesto de linealidad ejecutamos el test.

```{r}
# Test de normalidad
shapiro.test(modelo$residuals)
```

**Shapiro Test**

*[H0: Normal; H1: No normal]*

p-value \< 0.05 =\>  H1

## Homocedasticidad de residuos

Tambi茅n llamada homogenidad de varianzas, cuando la varianza de los residuos es constante. Si no lo es, diremos entonces que el modelo es heteroced谩stico.

**驴Porque es un problema cuando no se cumple?**

Si existe un patr贸n puede ser que el modelo no funcione bien. Se asume que el error del modelo de regresi贸n no afecta a la varinza o dispersi贸n de la estimaci贸n.

**驴Como detectarlo?**

a)  Gra铆fico de dispersi贸n teniendo los residuos estandarizados en el eje Y, y lo valores pronosticados en el eje X. (la l铆nea roja deben tender a ser horizontal)

b)  Test Breusch Pagan [H0: Existe homocedasticidad]

```{r}
# Grafico
plot(modelo, 3)
```

Se puede ver claramente como no estamos frente a un modelo homocedastico, ya que ni los puntos estan uniformemente distribuidos ni la linea roja es horizontal.

Para corroborar la no homocedasticidad:

```{r}
# Test BP
if(!require('car')){install.packages("car")}
library(car)
ncvTest(modelo)
```

**Non-constant Variance Score Test**

*[H0: Homocedasticidad; H1: No homocedasticidad]*

p-valor \< 0.05 =\> H1 

## Ausencia de multicolinealidad

Se produce cuando existe una fuerte o total correlaci贸n entre las varaibles independientes (x).

**驴Por que es un problema cuando se presenta?**

Cuando la colinealidad es alta produce coeficientes muy inestables en la ecuaci贸n. En otras palabras, los efectos atribuidos a las varaibles independientes pueden ser enga帽osos.

**驴Como detectarlo?**

Analizando el estad铆stico VIF(factor de inflaci贸n de varianza). Cuando VIF \>5, hay problemas de multicolinealidad

```{r}
# Test VIF
if(!require('DescTools')){install.packages("DescTools")}
library(DescTools)
VIF(modelo)
```

Todos los VIF son menores a 5, es decir, no tenemos un escenario de multicolinealidad. 

## Identificaci贸n de valores influyentes

Una observacion influyente se define como una observaci贸n que se diferencia marcadamente del conjunto de datos y tiene una gran influencia en el resultado del modelo, es decir, que no solo son outliers.

**驴Por que son un problema?**

Porque afectan los coeficientes de la ecuaci贸n y generan errores de predicci贸n

**驴Como detectarlos?**

Se utilizan medidas de influencia, entre las que resalta la distancia de Cook. LA distancia de Cook indica que un caso es un valor influyente cuando DCook \>=1

```{r}
# Grafico
plot(modelo, 4)
```

Es importante ver la escala del gfico, ya que, en este caso, ninguno pasa del valor 1.

```{r}
plot(modelo, 5)
```

No hay ningua observaci贸n que pase de las regiones del grafico.

```{r}
# Distancia de cook
data$cook=cooks.distance(modelo)
which(data$cook > 1)
```
