# Regresión Lineal: Requisitos

Font: Data Política (<https://www.youtube.com/watch?v=FGpfhKwsluE&list=WL&index=1>)

```{r}
# Abrimos la base de datos
if(!require('rio')){install.packages("rio")}
library(rio)
ruta_data=file.choose()
data = import(ruta_data)
```

```{r}
# Construimos el modelo
formula= data$salario_actual~data$salario_inicial + data$experiencia + data$antiguedad
modelo=lm(formula)
summary(modelo)
```

Preguntas para poder validar un modelo:

-   p-valor \< 0.05 =\> Modelo vàlido 🟢

-   R² Ajustado =\> Explica un 80% de la variabilitat de y

-   Cada una de les variables independents aporta al model

# Supuestos

Para verifiacar un modelo lineal necessitamos verificar que se cumplan los siguientes supuestos:

-   Linealidad

-   Normalidad de residuos

-   Homocedasticidad (Hmogeneidad de variancias)

-   Ausencia de multicolinealidad

-   Ausencia de valores influyentes

## Linealidad

La linealidad se produce cuando exsite relacion linela entre las varaibles independientes y la varaible dependiente.

**¿Porque es un problema cuando no se cumple?**

Porque se pueden considerar variables que no aporten al modelo. Tambien porque pueden existir otras relaciones no lineales que no son vistas previamente.

**¿Como detectarlo?**

Con verificación gràfica: Diagrama de dispersión entre los valores predichos y los residuos (la línea de tenencia debe ser horizontal) O pruebas de linealidad para cada una de las varaibles independientes.

```{r}
plot(modelo, 1)
```

Vemos un grafico de los valores predixos i cada uno de los residuos, la linea roja se aleja de la linia puntual. Solo viendo el grafico podriamos decir que hay un problema en el supuesto de linealidad, tendriamos que verificar linealida para cada una de las varaibales independientes con la dependiente.

```{r}
cor.test(data$salario_actual, data$salario_inicial)
```

**Test de Pearson**

*[(p-value \< 0.05) = (H0: No existe correlacion lineal; H1: Existe correlación lineal)]*

Relación lineal 🟢

```{r}
cor.test(data$salario_actual, data$experiencia)
```

🟢

```{r}
cor.test(data$salario_actual, data$antiguedad)
```

🔴 No cumple linealidad con la variable independiente, podriamos excluirla o analizar porque no es lineal.

## Normalidad de residuos

La normalidad de residuos existe cuando los residuos (no tipificados) del modelo no siguen una distribución normal.

**¿Porque es un problema cuando no se cumple?**

Porque no se podrían aplicar pruebas de validación global del modelo (ANOVA). Estas tienen como principal requerimiento que exista normalidad.

**¿Como detectarlo?**

Con un qqplot o realizar una prueba de normalidad (Shapiro Test)

```{r}
# Gràfico
plot(modelo, 2)
```

En un supuesto de liniealidad esperamos ver como todos los residuos siguen la linia daigonal. En este casa, y aunque la mayoria de puntos lo cumplen tenemos una disperción hacia el final e inicio del gràfico, para una cuantificación del supuesto de linealidad ejecutamos el test.

```{r}
# Test de normalidad
shapiro.test(modelo$residuals)
```

**Shapiro Test**

*[H0: Normal; H1: No normal]*

p-value \< 0.05 =\> 🔴 H1

## Homocedasticidad de residuos

También llamada homogenidad de varianzas, cuando la varianza de los residuos es constante. Si no lo es, diremos entonces que el modelo es heterocedástico.

**¿Porque es un problema cuando no se cumple?**

Si existe un patrón puede ser que el modelo no funcione bien. Se asume que el error del modelo de regresión no afecta a la varinza o dispersión de la estimación.

**¿Como detectarlo?**

a)  Graífico de dispersión teniendo los residuos estandarizados en el eje Y, y lo valores pronosticados en el eje X. (la línea roja deben tender a ser horizontal)

b)  Test Breusch Pagan [H0: Existe homocedasticidad]

```{r}
# Grafico
plot(modelo, 3)
```

Se puede ver claramente como no estamos frente a un modelo homocedastico, ya que ni los puntos estan uniformemente distribuidos ni la linea roja es horizontal.

Para corroborar la no homocedasticidad:

```{r}
# Test BP
if(!require('car')){install.packages("car")}
library(car)
ncvTest(modelo)
```

**Non-constant Variance Score Test**

*[H0: Homocedasticidad; H1: No homocedasticidad]*

p-valor \< 0.05 =\> H1 🔴

## Ausencia de multicolinealidad

Se produce cuando existe una fuerte o total correlación entre las varaibles independientes (x).

**¿Por que es un problema cuando se presenta?**

Cuando la colinealidad es alta produce coeficientes muy inestables en la ecuación. En otras palabras, los efectos atribuidos a las varaibles independientes pueden ser engañosos.

**¿Como detectarlo?**

Analizando el estadístico VIF(factor de inflación de varianza). Cuando VIF \>5, hay problemas de multicolinealidad

```{r}
# Test VIF
if(!require('DescTools')){install.packages("DescTools")}
library(DescTools)
VIF(modelo)
```

Todos los VIF son menores a 5, es decir, no tenemos un escenario de multicolinealidad. 🟢

## Identificación de valores influyentes

Una observacion influyente se define como una observación que se diferencia marcadamente del conjunto de datos y tiene una gran influencia en el resultado del modelo, es decir, que no solo son outliers.

**¿Por que son un problema?**

Porque afectan los coeficientes de la ecuación y generan errores de predicción

**¿Como detectarlos?**

Se utilizan medidas de influencia, entre las que resalta la distancia de Cook. LA distancia de Cook indica que un caso es un valor influyente cuando DCook \>=1

```{r}
# Grafico
plot(modelo, 4)
```

Es importante ver la escala del gàfico, ya que, en este caso, ninguno pasa del valor 1.

```{r}
plot(modelo, 5)
```

No hay ningua observación que pase de las regiones del grafico.

```{r}
# Distancia de cook
data$cook=cooks.distance(modelo)
which(data$cook > 1)
```
